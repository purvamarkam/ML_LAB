{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfMB/K4JLmoeFNr5YXWHvF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purvamarkam/ML_LAB/blob/main/Assignment10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ8lkyYnp_lp",
        "outputId": "765a5fa8-1dc9-457a-920c-21f19ed1c070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded data! Shape: (569, 33)\n",
            " Dropped 'id' column.\n",
            "\n",
            "Checking for missing values:\n",
            "diagnosis                    0\n",
            "radius_mean                  0\n",
            "texture_mean                 0\n",
            "perimeter_mean               0\n",
            "area_mean                    0\n",
            "smoothness_mean              0\n",
            "compactness_mean             0\n",
            "concavity_mean               0\n",
            "concave points_mean          0\n",
            "symmetry_mean                0\n",
            "fractal_dimension_mean       0\n",
            "radius_se                    0\n",
            "texture_se                   0\n",
            "perimeter_se                 0\n",
            "area_se                      0\n",
            "smoothness_se                0\n",
            "compactness_se               0\n",
            "concavity_se                 0\n",
            "concave points_se            0\n",
            "symmetry_se                  0\n",
            "fractal_dimension_se         0\n",
            "radius_worst                 0\n",
            "texture_worst                0\n",
            "perimeter_worst              0\n",
            "area_worst                   0\n",
            "smoothness_worst             0\n",
            "compactness_worst            0\n",
            "concavity_worst              0\n",
            "concave points_worst         0\n",
            "symmetry_worst               0\n",
            "fractal_dimension_worst      0\n",
            "Unnamed: 32                569\n",
            " Encoded 'diagnosis': M â†’ 1, B â†’ 0\n",
            " Features: (569, 31), Target: (569,)\n",
            " Moved 120 malignant cases to test set.\n",
            "Train size: 335,  Test size: 234\n",
            " Tree 1 â†’ Accuracy: 0.9851\n",
            " Tree 2 â†’ Accuracy: 0.9791\n",
            " Tree 3 â†’ Accuracy: 0.9821\n",
            " Tree 4 â†’ Accuracy: 0.9731\n",
            " Tree 5 â†’ Accuracy: 0.9761\n",
            " Tree 6 â†’ Accuracy: 0.9821\n",
            " Tree 7 â†’ Accuracy: 0.9731\n",
            " Tree 8 â†’ Accuracy: 0.9881\n",
            " Tree 9 â†’ Accuracy: 0.9851\n",
            " Tree 10 â†’ Accuracy: 0.9851\n",
            "\n",
            "Top 10 Features:\n",
            "1. perimeter_mean\n",
            "2. area_worst\n",
            "3. concave points_mean\n",
            "4. concavity_worst\n",
            "5. radius_worst\n",
            "6. compactness_mean\n",
            "7. radius_mean\n",
            "8. concavity_mean\n",
            "9. area_se\n",
            "10. texture_worst\n",
            "Retrained Tree 1 Accuracy: 0.9910\n",
            "Retrained Tree 2 Accuracy: 0.9940\n",
            "Retrained Tree 3 Accuracy: 0.9821\n",
            "Retrained Tree 4 Accuracy: 0.9731\n",
            "Retrained Tree 5 Accuracy: 0.9851\n",
            "Retrained Tree 6 Accuracy: 0.9910\n",
            "Retrained Tree 7 Accuracy: 0.9731\n",
            "Retrained Tree 8 Accuracy: 0.9851\n",
            "Retrained Tree 9 Accuracy: 0.9731\n",
            "Retrained Tree 10 Accuracy: 0.9881\n",
            "\n",
            "Final Model Evaluation:\n",
            "ðŸ”¹ Logistic Regression: Accuracy = 0.9188, Recall = 0.8827\n",
            "ðŸ”¸ Master Tree: Accuracy = 0.8291, Recall = 0.7531\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, recall_score\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "# Load & Preprocess\n",
        "\n",
        "def load_and_preprocess_data(filepath):\n",
        "    data = pd.read_csv(filepath)\n",
        "    print(f\" Loaded data! Shape: {data.shape}\")\n",
        "\n",
        "    if 'id' in data.columns:\n",
        "        data = data.drop(columns=['id'])\n",
        "        print(\" Dropped 'id' column.\")\n",
        "\n",
        "    print(\"\\nChecking for missing values:\")\n",
        "    print(data.isnull().sum().to_string())\n",
        "\n",
        "    data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
        "    print(\" Encoded 'diagnosis': M â†’ 1, B â†’ 0\")\n",
        "\n",
        "    X = data.drop(columns=['diagnosis'])\n",
        "    y = data['diagnosis']\n",
        "    print(f\" Features: {X.shape}, Target: {y.shape}\")\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# Skewed Split\n",
        "\n",
        "def skew_train_test_split(X, y, n_move=120, random_state=42):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=random_state\n",
        "    )\n",
        "\n",
        "    train_df = pd.concat([X_train, y_train], axis=1)\n",
        "    test_df = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "    m_class_rows = train_df[train_df['diagnosis'] == 1]\n",
        "    to_move = m_class_rows.sample(n=n_move, random_state=random_state)\n",
        "\n",
        "    train_df = train_df.drop(to_move.index)\n",
        "    test_df = pd.concat([test_df, to_move])\n",
        "\n",
        "    print(f\" Moved {n_move} malignant cases to test set.\")\n",
        "    print(f\"Train size: {train_df.shape[0]},  Test size: {test_df.shape[0]}\")\n",
        "\n",
        "    X_train = train_df.drop(columns=['diagnosis'])\n",
        "    y_train = train_df['diagnosis']\n",
        "    X_test = test_df.drop(columns=['diagnosis'])\n",
        "    y_test = test_df['diagnosis']\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "#  Train Ensemble\n",
        "\n",
        "def train_decision_trees(X_train, y_train, n_trees=10):\n",
        "    trees, accuracies, importances = [], [], []\n",
        "\n",
        "    for i in range(n_trees):\n",
        "        idx = np.random.choice(X_train.index, size=len(X_train), replace=True)\n",
        "        X_sample = X_train.loc[idx]\n",
        "        y_sample = y_train.loc[idx]\n",
        "\n",
        "        tree = DecisionTreeClassifier(max_features='sqrt', class_weight='balanced', random_state=i)\n",
        "        tree.fit(X_sample, y_sample)\n",
        "\n",
        "        acc = accuracy_score(y_train, tree.predict(X_train))\n",
        "        print(f\" Tree {i+1} â†’ Accuracy: {acc:.4f}\")\n",
        "\n",
        "        trees.append(tree)\n",
        "        accuracies.append(acc)\n",
        "        importances.append(tree.feature_importances_)\n",
        "\n",
        "    return trees, accuracies, importances\n",
        "\n",
        "\n",
        "#  Select Top Features\n",
        "\n",
        "def get_top_features_simple(importances, feature_names, top_n=10):\n",
        "    avg_importance = np.mean(np.array(importances), axis=0)\n",
        "    top_indices = np.argsort(avg_importance)[::-1][:top_n]\n",
        "    top_features = [feature_names[i] for i in top_indices]\n",
        "\n",
        "    print(f\"\\nTop {top_n} Features:\")\n",
        "    for i, feature in enumerate(top_features):\n",
        "        print(f\"{i+1}. {feature}\")\n",
        "    return top_features\n",
        "\n",
        "\n",
        "#  Retrain on Top Features\n",
        "\n",
        "def retrain_decision_trees_on_selected_features(X_train_selected, y_train, n_trees=10):\n",
        "    trees, accuracies = [], []\n",
        "\n",
        "    for i in range(n_trees):\n",
        "        idx = np.random.choice(X_train_selected.index, size=len(X_train_selected), replace=True)\n",
        "        X_sample = X_train_selected.loc[idx]\n",
        "        y_sample = y_train.loc[idx]\n",
        "\n",
        "        tree = DecisionTreeClassifier(max_features='sqrt', class_weight='balanced', random_state=100+i)\n",
        "        tree.fit(X_sample, y_sample)\n",
        "\n",
        "        acc = accuracy_score(y_train, tree.predict(X_train_selected))\n",
        "        print(f\"Retrained Tree {i+1} Accuracy: {acc:.4f}\")\n",
        "\n",
        "        trees.append(tree)\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    return trees, accuracies\n",
        "\n",
        "# Train Final Models\n",
        "\n",
        "def train_final_models(retrained_trees, X_train_selected, y_train):\n",
        "    tree_preds = [tree.predict(X_train_selected) for tree in retrained_trees]\n",
        "    tree_preds_matrix = np.column_stack(tree_preds)\n",
        "\n",
        "    X_combined = pd.concat([\n",
        "        X_train_selected.reset_index(drop=True),\n",
        "        pd.DataFrame(tree_preds_matrix, columns=[f\"tree_{i+1}\" for i in range(len(retrained_trees))])\n",
        "    ], axis=1)\n",
        "\n",
        "    log_model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "    log_model.fit(X_combined, y_train)\n",
        "\n",
        "    master_tree = DecisionTreeClassifier(class_weight='balanced', max_features='sqrt', random_state=200)\n",
        "    master_tree.fit(X_combined, y_train)\n",
        "\n",
        "    return log_model, master_tree\n",
        "\n",
        "\n",
        "# Evaluate Final Models\n",
        "\n",
        "def evaluate_final_models(retrained_trees, log_model, master_tree, X_test_selected, y_test):\n",
        "    test_tree_preds = [tree.predict(X_test_selected) for tree in retrained_trees]\n",
        "    test_preds_matrix = np.column_stack(test_tree_preds)\n",
        "\n",
        "    X_test_combined = pd.concat([\n",
        "        X_test_selected.reset_index(drop=True),\n",
        "        pd.DataFrame(test_preds_matrix, columns=[f\"tree_{i+1}\" for i in range(len(retrained_trees))])\n",
        "    ], axis=1)\n",
        "\n",
        "    y_pred_log = log_model.predict(X_test_combined)\n",
        "    acc_log = accuracy_score(y_test, y_pred_log)\n",
        "    recall_log = recall_score(y_test, y_pred_log)\n",
        "\n",
        "    y_pred_tree = master_tree.predict(X_test_combined)\n",
        "    acc_tree = accuracy_score(y_test, y_pred_tree)\n",
        "    recall_tree = recall_score(y_test, y_pred_tree)\n",
        "\n",
        "    print(\"\\nFinal Model Evaluation:\")\n",
        "    print(f\"ðŸ”¹ Logistic Regression: Accuracy = {acc_log:.4f}, Recall = {recall_log:.4f}\")\n",
        "    print(f\"ðŸ”¸ Master Tree: Accuracy = {acc_tree:.4f}, Recall = {recall_tree:.4f}\")\n",
        "\n",
        "    return acc_log, recall_log, acc_tree, recall_tree\n",
        "\n",
        "\n",
        "def main_pipeline():\n",
        "    # Replace with the correct file path\n",
        "    file_path = 'Cancer_Data.csv'\n",
        "\n",
        "    X, y = load_and_preprocess_data(file_path)\n",
        "    X_train, X_test, y_train, y_test = skew_train_test_split(X, y)\n",
        "\n",
        "    trees, accuracies, importances = train_decision_trees(X_train, y_train)\n",
        "    top_features = get_top_features_simple(importances, X_train.columns, top_n=10)\n",
        "\n",
        "    X_train_selected = X_train[top_features]\n",
        "    X_test_selected = X_test[top_features]\n",
        "\n",
        "    retrained_trees, _ = retrain_decision_trees_on_selected_features(X_train_selected, y_train)\n",
        "    log_model, master_tree = train_final_models(retrained_trees, X_train_selected, y_train)\n",
        "    evaluate_final_models(retrained_trees, log_model, master_tree, X_test_selected, y_test)\n",
        "main_pipeline()"
      ]
    }
  ]
}